{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9793ef6a",
   "metadata": {},
   "source": [
    "# NLTK with Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d49afc39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e76cfa92",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "05018ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "syn = wordnet.synsets('pantry')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0549033b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Synset('pantry.n.01')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "syn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e6fec77d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "syn.examples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e01950f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a small storeroom for storing foods or wines'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "syn.definition()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7e79672c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('storeroom.n.01')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "syn.hypernyms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3985bbbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('stillroom.n.01')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "syn.hyponyms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6390dea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "syn2= wordnet.synsets('Backing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b3a3718f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('backing.n.01'),\n",
       " Synset('backing.n.02'),\n",
       " Synset('support.n.11'),\n",
       " Synset('back.v.01'),\n",
       " Synset('back.v.02'),\n",
       " Synset('second.v.01'),\n",
       " Synset('back.v.04'),\n",
       " Synset('back.v.05'),\n",
       " Synset('back.v.06'),\n",
       " Synset('bet_on.v.01'),\n",
       " Synset('back.v.08'),\n",
       " Synset('back.v.09'),\n",
       " Synset('back.v.10')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "syn2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d72a572b",
   "metadata": {},
   "outputs": [],
   "source": [
    "syn2= wordnet.synsets('Backing')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "64c88dab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Synset('backing.n.01')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "syn2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "df610786",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To find the similarity between these 2 words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "852a49a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "syn.wup_similarity(syn2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2818e271",
   "metadata": {},
   "outputs": [],
   "source": [
    "syn3 = wordnet.synsets('Bird')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3c5b0ce8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Synset('bird.n.01')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "syn3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c1af9956",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "syn.wup_similarity(syn3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c12de478",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which means pantry and backing having 0.1 similarity. But pantry and bird is having 0.4 simility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fcc46ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "synonyms = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "035d2c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "antonyms = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cae3bf91",
   "metadata": {},
   "outputs": [],
   "source": [
    "syn = wordnet.synsets('Backing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9829af7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('backing.n.01'),\n",
       " Synset('backing.n.02'),\n",
       " Synset('support.n.11'),\n",
       " Synset('back.v.01'),\n",
       " Synset('back.v.02'),\n",
       " Synset('second.v.01'),\n",
       " Synset('back.v.04'),\n",
       " Synset('back.v.05'),\n",
       " Synset('back.v.06'),\n",
       " Synset('bet_on.v.01'),\n",
       " Synset('back.v.08'),\n",
       " Synset('back.v.09'),\n",
       " Synset('back.v.10')]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "syn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "58dadabd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Lemma('backing.n.01.backing'),\n",
       " Lemma('backing.n.01.backup'),\n",
       " Lemma('backing.n.01.championship'),\n",
       " Lemma('backing.n.01.patronage')]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "syn[0].lemmas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "27f0565e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['backing', 'backup', 'championship', 'patronage']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "syn[0].lemma_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "16d1d2f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset('good.n.01')\n",
      "Synset('good.n.02')\n",
      "Synset('good.n.03')\n",
      "Synset('commodity.n.01')\n",
      "Synset('good.a.01')\n",
      "Synset('full.s.06')\n",
      "Synset('good.a.03')\n",
      "Synset('estimable.s.02')\n",
      "Synset('beneficial.s.01')\n",
      "Synset('good.s.06')\n",
      "Synset('good.s.07')\n",
      "Synset('adept.s.01')\n",
      "Synset('good.s.09')\n",
      "Synset('dear.s.02')\n",
      "Synset('dependable.s.04')\n",
      "Synset('good.s.12')\n",
      "Synset('good.s.13')\n",
      "Synset('effective.s.04')\n",
      "Synset('good.s.15')\n",
      "Synset('good.s.16')\n",
      "Synset('good.s.17')\n",
      "Synset('good.s.18')\n",
      "Synset('good.s.19')\n",
      "Synset('good.s.20')\n",
      "Synset('good.s.21')\n",
      "Synset('well.r.01')\n",
      "Synset('thoroughly.r.02')\n"
     ]
    }
   ],
   "source": [
    "for syn in wordnet.synsets('Good'):\n",
    "    print(syn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cc3bdc3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "good\n",
      "good\n",
      "goodness\n",
      "good\n",
      "goodness\n",
      "commodity\n",
      "trade_good\n",
      "good\n",
      "good\n",
      "full\n",
      "good\n",
      "good\n",
      "estimable\n",
      "good\n",
      "honorable\n",
      "respectable\n",
      "beneficial\n",
      "good\n",
      "good\n",
      "good\n",
      "just\n",
      "upright\n",
      "adept\n",
      "expert\n",
      "good\n",
      "practiced\n",
      "proficient\n",
      "skillful\n",
      "skilful\n",
      "good\n",
      "dear\n",
      "good\n",
      "near\n",
      "dependable\n",
      "good\n",
      "safe\n",
      "secure\n",
      "good\n",
      "right\n",
      "ripe\n",
      "good\n",
      "well\n",
      "effective\n",
      "good\n",
      "in_effect\n",
      "in_force\n",
      "good\n",
      "good\n",
      "serious\n",
      "good\n",
      "sound\n",
      "good\n",
      "salutary\n",
      "good\n",
      "honest\n",
      "good\n",
      "undecomposed\n",
      "unspoiled\n",
      "unspoilt\n",
      "good\n",
      "well\n",
      "good\n",
      "thoroughly\n",
      "soundly\n",
      "good\n"
     ]
    }
   ],
   "source": [
    "for syn in wordnet.synsets('Good'):\n",
    "    for i in syn.lemmas():\n",
    "        print(i.name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dab631ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "for syn in wordnet.synsets('Good'):\n",
    "    for i in syn.lemmas():\n",
    "        synonyms.append(i.name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d17709a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['good',\n",
       " 'good',\n",
       " 'goodness',\n",
       " 'good',\n",
       " 'goodness',\n",
       " 'commodity',\n",
       " 'trade_good',\n",
       " 'good',\n",
       " 'good',\n",
       " 'full',\n",
       " 'good',\n",
       " 'good',\n",
       " 'estimable',\n",
       " 'good',\n",
       " 'honorable',\n",
       " 'respectable',\n",
       " 'beneficial',\n",
       " 'good',\n",
       " 'good',\n",
       " 'good',\n",
       " 'just',\n",
       " 'upright',\n",
       " 'adept',\n",
       " 'expert',\n",
       " 'good',\n",
       " 'practiced',\n",
       " 'proficient',\n",
       " 'skillful',\n",
       " 'skilful',\n",
       " 'good',\n",
       " 'dear',\n",
       " 'good',\n",
       " 'near',\n",
       " 'dependable',\n",
       " 'good',\n",
       " 'safe',\n",
       " 'secure',\n",
       " 'good',\n",
       " 'right',\n",
       " 'ripe',\n",
       " 'good',\n",
       " 'well',\n",
       " 'effective',\n",
       " 'good',\n",
       " 'in_effect',\n",
       " 'in_force',\n",
       " 'good',\n",
       " 'good',\n",
       " 'serious',\n",
       " 'good',\n",
       " 'sound',\n",
       " 'good',\n",
       " 'salutary',\n",
       " 'good',\n",
       " 'honest',\n",
       " 'good',\n",
       " 'undecomposed',\n",
       " 'unspoiled',\n",
       " 'unspoilt',\n",
       " 'good',\n",
       " 'well',\n",
       " 'good',\n",
       " 'thoroughly',\n",
       " 'soundly',\n",
       " 'good']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synonyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d9c0ef78",
   "metadata": {},
   "outputs": [],
   "source": [
    "for syn in wordnet.synsets('Good'):\n",
    "    for i in syn.lemmas():\n",
    "        antonyms.append(i.antonyms())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "db3da984",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[],\n",
       " [Lemma('evil.n.03.evil')],\n",
       " [Lemma('evil.n.03.evilness')],\n",
       " [Lemma('bad.n.01.bad')],\n",
       " [Lemma('bad.n.01.badness')],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [Lemma('bad.a.01.bad')],\n",
       " [],\n",
       " [],\n",
       " [Lemma('evil.a.01.evil')],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [Lemma('ill.r.01.ill')],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " []]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "antonyms"
   ]
  },
  {
   "cell_type": "raw",
   "id": "678bf3cd",
   "metadata": {},
   "source": [
    "Lemmatization is the process of reducing inflected forms of a word while still ensuring that the reduced form belongs to the language. This reduced form, or root word, is called a lemma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a45af611",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a578c85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame({'Name':['Archana','Mani','Kalp','Thiru'], 'Place':['Salem','Trichy','Madurai','Coimbatore']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e0324126",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Place</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Archana</td>\n",
       "      <td>Salem</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mani</td>\n",
       "      <td>Trichy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kalp</td>\n",
       "      <td>Madurai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Thiru</td>\n",
       "      <td>Coimbatore</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Name       Place\n",
       "0  Archana       Salem\n",
       "1     Mani      Trichy\n",
       "2     Kalp     Madurai\n",
       "3    Thiru  Coimbatore"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7a0bd822",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "66ec5f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Tokenized_Name'] = data['Name'].apply(word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "004789a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [Archana]\n",
       "1       [Mani]\n",
       "2       [Kalp]\n",
       "3      [Thiru]\n",
       "Name: Tokenized_Name, dtype: object"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Tokenized_Name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c9a2f343",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data['Tokenized_Name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8bcc3d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Tokenized_Place'] = data['Place'].apply(word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ee444cbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         [Salem]\n",
       "1        [Trichy]\n",
       "2       [Madurai]\n",
       "3    [Coimbatore]\n",
       "Name: Tokenized_Place, dtype: object"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Tokenized_Place']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "45e50a91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Archana']\n",
      "['Mani']\n",
      "['Kalp']\n",
      "['Thiru']\n"
     ]
    }
   ],
   "source": [
    "for i in data['Tokenized_Name']:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "959be1b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Archana', 'NNP')]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.pos_tag(data['Tokenized_Name'][0]) # NNP proper noun, singular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "17c1dea1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Mani', 'NN')]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.pos_tag(data['Tokenized_Name'][1]) # NN noun, singular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8c2cc3c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Salem', 'NN')]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.pos_tag(data['Tokenized_Place'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b9ac92b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Trichy', 'NN')]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.pos_tag(data['Tokenized_Place'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6a0b11b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f49273ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6aa9563a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a',\n",
       " 'about',\n",
       " 'above',\n",
       " 'after',\n",
       " 'again',\n",
       " 'against',\n",
       " 'ain',\n",
       " 'all',\n",
       " 'am',\n",
       " 'an',\n",
       " 'and',\n",
       " 'any',\n",
       " 'are',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'as',\n",
       " 'at',\n",
       " 'be',\n",
       " 'because',\n",
       " 'been',\n",
       " 'before',\n",
       " 'being',\n",
       " 'below',\n",
       " 'between',\n",
       " 'both',\n",
       " 'but',\n",
       " 'by',\n",
       " 'can',\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'd',\n",
       " 'did',\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'do',\n",
       " 'does',\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'doing',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'down',\n",
       " 'during',\n",
       " 'each',\n",
       " 'few',\n",
       " 'for',\n",
       " 'from',\n",
       " 'further',\n",
       " 'had',\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'has',\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'have',\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'having',\n",
       " 'he',\n",
       " 'her',\n",
       " 'here',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'him',\n",
       " 'himself',\n",
       " 'his',\n",
       " 'how',\n",
       " 'i',\n",
       " 'if',\n",
       " 'in',\n",
       " 'into',\n",
       " 'is',\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'just',\n",
       " 'll',\n",
       " 'm',\n",
       " 'ma',\n",
       " 'me',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'more',\n",
       " 'most',\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'my',\n",
       " 'myself',\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'now',\n",
       " 'o',\n",
       " 'of',\n",
       " 'off',\n",
       " 'on',\n",
       " 'once',\n",
       " 'only',\n",
       " 'or',\n",
       " 'other',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'out',\n",
       " 'over',\n",
       " 'own',\n",
       " 're',\n",
       " 's',\n",
       " 'same',\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'so',\n",
       " 'some',\n",
       " 'such',\n",
       " 't',\n",
       " 'than',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'the',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'them',\n",
       " 'themselves',\n",
       " 'then',\n",
       " 'there',\n",
       " 'these',\n",
       " 'they',\n",
       " 'this',\n",
       " 'those',\n",
       " 'through',\n",
       " 'to',\n",
       " 'too',\n",
       " 'under',\n",
       " 'until',\n",
       " 'up',\n",
       " 've',\n",
       " 'very',\n",
       " 'was',\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'we',\n",
       " 'were',\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'what',\n",
       " 'when',\n",
       " 'where',\n",
       " 'which',\n",
       " 'while',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'why',\n",
       " 'will',\n",
       " 'with',\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\",\n",
       " 'y',\n",
       " 'you',\n",
       " \"you'd\",\n",
       " \"you'll\",\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves'}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f79e6c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Filtered_Name'] = data['Tokenized_Name'].apply(lambda x:[word for word in x if word.lower() not in stop_words])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7f8f1cd6",
   "metadata": {},
   "source": [
    "[word for word in x if word.lower() not in stop_words]: This is a list comprehension that iterates over each word (word) in the tokenized text (x). For each word, it checks if the lowercase version of the word is not in the set of stopwords (stop_words). If the word is not a stopword, it keeps it in the list. Otherwise, it is filtered out.\n",
    "\n",
    "So, overall, this line of code creates a new column called 'Filtered_Text' in the DataFrame, where each element is a list of words from the 'Tokenized_Text' column with stopwords removed. This process effectively filters out common words (stopwords) that do not carry significant meaning for many NLP tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "1ff53801",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [Archana]\n",
       "1       [Mani]\n",
       "2       [Kalp]\n",
       "3      [Thiru]\n",
       "Name: Filtered_Name, dtype: object"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Filtered_Name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "6daf89d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "85f1eb3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d3a36a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Lemmatized_Name'] = data['Filtered_Name'].apply(lambda x:[lemmatizer.lemmatize(word) for word in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "6ee12444",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [Archana]\n",
       "1       [Mani]\n",
       "2       [Kalp]\n",
       "3      [Thiru]\n",
       "Name: Lemmatized_Name, dtype: object"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Lemmatized_Name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "84afc82b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Place</th>\n",
       "      <th>Lemmatized_Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Archana</td>\n",
       "      <td>Salem</td>\n",
       "      <td>[Archana]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mani</td>\n",
       "      <td>Trichy</td>\n",
       "      <td>[Mani]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kalp</td>\n",
       "      <td>Madurai</td>\n",
       "      <td>[Kalp]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Thiru</td>\n",
       "      <td>Coimbatore</td>\n",
       "      <td>[Thiru]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Name       Place Lemmatized_Name\n",
       "0  Archana       Salem       [Archana]\n",
       "1     Mani      Trichy          [Mani]\n",
       "2     Kalp     Madurai          [Kalp]\n",
       "3    Thiru  Coimbatore         [Thiru]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[['Name','Place','Lemmatized_Name']]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "bd930f6d",
   "metadata": {},
   "source": [
    "[lemmatizer.lemmatize(word) for word in x]: This is a list comprehension that iterates over each word (word) in the filtered text (x). For each word, it applies lemmatization using the lemmatizer.lemmatize() function from NLTK's WordNetLemmatizer class. Lemmatization reduces words to their base or dictionary form, considering the word's morphological variations.\n",
    "\n",
    "lemmatizer.lemmatize(word): This method takes a word as input and returns its lemma (base form). For example, \"running\" becomes \"run\", \"better\" becomes \"good\", etc.\n",
    "for word in x: This iterates over each word in the filtered text.\n",
    "So, overall, this line of code creates a new column called 'Lemmatized_Name' in the DataFrame or dictionary data, where each element is a list of lemmatized words derived from the corresponding filtered text in the 'Filtered_Name' column. This process aims to standardize words to their base forms, which can be useful for various NLP tasks such as text analysis, information retrieval, and machine learning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46c25adf",
   "metadata": {},
   "source": [
    "# Using dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "6546a5b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "worldcities = pd.read_csv('C:/Users/91701/Desktop/Dataset/worldcities.csv',encoding='latin1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "04f0caba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>city_ascii</th>\n",
       "      <th>lat</th>\n",
       "      <th>lng</th>\n",
       "      <th>pop</th>\n",
       "      <th>country</th>\n",
       "      <th>iso2</th>\n",
       "      <th>iso3</th>\n",
       "      <th>province</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Qal eh-ye Now</td>\n",
       "      <td>Qal eh-ye</td>\n",
       "      <td>34.983000</td>\n",
       "      <td>63.133300</td>\n",
       "      <td>2997.0</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>AF</td>\n",
       "      <td>AFG</td>\n",
       "      <td>Badghis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Chaghcharan</td>\n",
       "      <td>Chaghcharan</td>\n",
       "      <td>34.516701</td>\n",
       "      <td>65.250001</td>\n",
       "      <td>15000.0</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>AF</td>\n",
       "      <td>AFG</td>\n",
       "      <td>Ghor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lashkar Gah</td>\n",
       "      <td>Lashkar Gah</td>\n",
       "      <td>31.582998</td>\n",
       "      <td>64.360000</td>\n",
       "      <td>201546.0</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>AF</td>\n",
       "      <td>AFG</td>\n",
       "      <td>Hilmand</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Zaranj</td>\n",
       "      <td>Zaranj</td>\n",
       "      <td>31.112001</td>\n",
       "      <td>61.886998</td>\n",
       "      <td>49851.0</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>AF</td>\n",
       "      <td>AFG</td>\n",
       "      <td>Nimroz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tarin Kowt</td>\n",
       "      <td>Tarin Kowt</td>\n",
       "      <td>32.633298</td>\n",
       "      <td>65.866699</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>AF</td>\n",
       "      <td>AFG</td>\n",
       "      <td>Uruzgan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7317</th>\n",
       "      <td>Mutare</td>\n",
       "      <td>Mutare</td>\n",
       "      <td>-18.970019</td>\n",
       "      <td>32.650038</td>\n",
       "      <td>216785.0</td>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>ZW</td>\n",
       "      <td>ZWE</td>\n",
       "      <td>Manicaland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7318</th>\n",
       "      <td>Kadoma</td>\n",
       "      <td>Kadoma</td>\n",
       "      <td>-18.330006</td>\n",
       "      <td>29.909947</td>\n",
       "      <td>56400.0</td>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>ZW</td>\n",
       "      <td>ZWE</td>\n",
       "      <td>Mashonaland West</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7319</th>\n",
       "      <td>Chitungwiza</td>\n",
       "      <td>Chitungwiza</td>\n",
       "      <td>-18.000001</td>\n",
       "      <td>31.100003</td>\n",
       "      <td>331071.0</td>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>ZW</td>\n",
       "      <td>ZWE</td>\n",
       "      <td>Harare</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7320</th>\n",
       "      <td>Harare</td>\n",
       "      <td>Harare</td>\n",
       "      <td>-17.817790</td>\n",
       "      <td>31.044709</td>\n",
       "      <td>1557406.5</td>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>ZW</td>\n",
       "      <td>ZWE</td>\n",
       "      <td>Harare</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7321</th>\n",
       "      <td>Bulawayo</td>\n",
       "      <td>Bulawayo</td>\n",
       "      <td>-20.169998</td>\n",
       "      <td>28.580002</td>\n",
       "      <td>697096.0</td>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>ZW</td>\n",
       "      <td>ZWE</td>\n",
       "      <td>Bulawayo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7322 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               city   city_ascii        lat        lng        pop  \\\n",
       "0     Qal eh-ye Now    Qal eh-ye  34.983000  63.133300     2997.0   \n",
       "1       Chaghcharan  Chaghcharan  34.516701  65.250001    15000.0   \n",
       "2       Lashkar Gah  Lashkar Gah  31.582998  64.360000   201546.0   \n",
       "3            Zaranj       Zaranj  31.112001  61.886998    49851.0   \n",
       "4        Tarin Kowt   Tarin Kowt  32.633298  65.866699    10000.0   \n",
       "...             ...          ...        ...        ...        ...   \n",
       "7317         Mutare       Mutare -18.970019  32.650038   216785.0   \n",
       "7318         Kadoma       Kadoma -18.330006  29.909947    56400.0   \n",
       "7319    Chitungwiza  Chitungwiza -18.000001  31.100003   331071.0   \n",
       "7320         Harare       Harare -17.817790  31.044709  1557406.5   \n",
       "7321       Bulawayo     Bulawayo -20.169998  28.580002   697096.0   \n",
       "\n",
       "          country iso2 iso3          province  \n",
       "0     Afghanistan   AF  AFG           Badghis  \n",
       "1     Afghanistan   AF  AFG              Ghor  \n",
       "2     Afghanistan   AF  AFG           Hilmand  \n",
       "3     Afghanistan   AF  AFG            Nimroz  \n",
       "4     Afghanistan   AF  AFG           Uruzgan  \n",
       "...           ...  ...  ...               ...  \n",
       "7317     Zimbabwe   ZW  ZWE        Manicaland  \n",
       "7318     Zimbabwe   ZW  ZWE  Mashonaland West  \n",
       "7319     Zimbabwe   ZW  ZWE            Harare  \n",
       "7320     Zimbabwe   ZW  ZWE            Harare  \n",
       "7321     Zimbabwe   ZW  ZWE          Bulawayo  \n",
       "\n",
       "[7322 rows x 9 columns]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "worldcities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "f7db07b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7322 entries, 0 to 7321\n",
      "Data columns (total 9 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   city        7322 non-null   object \n",
      " 1   city_ascii  7322 non-null   object \n",
      " 2   lat         7322 non-null   float64\n",
      " 3   lng         7322 non-null   float64\n",
      " 4   pop         7322 non-null   float64\n",
      " 5   country     7322 non-null   object \n",
      " 6   iso2        7291 non-null   object \n",
      " 7   iso3        7322 non-null   object \n",
      " 8   province    7203 non-null   object \n",
      "dtypes: float64(3), object(6)\n",
      "memory usage: 515.0+ KB\n"
     ]
    }
   ],
   "source": [
    "worldcities.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "acf3aff1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "city            0\n",
       "city_ascii      0\n",
       "lat             0\n",
       "lng             0\n",
       "pop             0\n",
       "country         0\n",
       "iso2           31\n",
       "iso3            0\n",
       "province      119\n",
       "dtype: int64"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "worldcities.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "92ab0cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "ebb816d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "worldcities['tokenized_city'] = worldcities['city'].apply(word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "a3f50b2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       [Qal, eh-ye, Now]\n",
       "1           [Chaghcharan]\n",
       "2          [Lashkar, Gah]\n",
       "3                [Zaranj]\n",
       "4           [Tarin, Kowt]\n",
       "              ...        \n",
       "7317             [Mutare]\n",
       "7318             [Kadoma]\n",
       "7319        [Chitungwiza]\n",
       "7320             [Harare]\n",
       "7321           [Bulawayo]\n",
       "Name: tokenized_city, Length: 7322, dtype: object"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "worldcities['tokenized_city']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "2ebaf73f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pos_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "287faf7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Qal eh-ye Now', 'JJ'),\n",
       " ('Chaghcharan', 'NNP'),\n",
       " ('Lashkar Gah', 'NNP'),\n",
       " ('Zaranj', 'NNP'),\n",
       " ('Tarin Kowt', 'NNP'),\n",
       " ('Zareh Sharan', 'NNP'),\n",
       " ('Asadabad', 'NNP'),\n",
       " ('Taloqan', 'NNP'),\n",
       " ('Mahmud-E Eraqi', 'NNP'),\n",
       " ('Mehtar Lam', 'NNP'),\n",
       " ('Baraki Barak', 'NNP'),\n",
       " ('Aybak', 'NNP'),\n",
       " ('Mayda Shahr', 'NNP'),\n",
       " ('Karokh', 'NNP'),\n",
       " ('Sheberghan', 'NNP'),\n",
       " ('Pol-e Khomri', 'NNP'),\n",
       " ('Balkh', 'NNP'),\n",
       " ('Meymaneh', 'NNP'),\n",
       " ('Andkhvoy', 'NNP'),\n",
       " ('Qalat', 'NNP'),\n",
       " ('Ghazni', 'NNP'),\n",
       " ('Feyzabad', 'NNP'),\n",
       " ('Kondoz', 'NNP'),\n",
       " ('Jalalabad', 'NNP'),\n",
       " ('Charikar', 'NNP'),\n",
       " ('Gardiz', 'NNP'),\n",
       " ('Bamian', 'NNP'),\n",
       " ('Baghlan', 'NNP'),\n",
       " ('Farah', 'NNP'),\n",
       " ('Herat', 'NNP'),\n",
       " ('Mazar-e Sharif', 'NNP'),\n",
       " ('Kandahar', 'NNP'),\n",
       " ('Kabul', 'NNP'),\n",
       " ('Mariehamn', 'NNP'),\n",
       " ('Kruje', 'NNP'),\n",
       " ('Fier', 'NNP'),\n",
       " ('Lushnje', 'NNP'),\n",
       " ('Puke', 'NNP'),\n",
       " ('Bajram Curri', 'NNP'),\n",
       " ('Kukes', 'NNP'),\n",
       " ('Sarande', 'NNP'),\n",
       " ('Erseke', 'NNP'),\n",
       " ('Pogradec', 'NNP'),\n",
       " ('Korce', 'NNP'),\n",
       " ('Berat', 'NNP'),\n",
       " ('Corovode', 'NNP'),\n",
       " ('Gramsh', 'NNP'),\n",
       " ('Librazhd', 'NNP'),\n",
       " ('Tepelene', 'NNP'),\n",
       " ('Permet', 'NNP'),\n",
       " ('Gjirokaster', 'NNP'),\n",
       " ('Peshkopi', 'NNP'),\n",
       " ('Burrel', 'NNP'),\n",
       " ('Lezhe', 'NNP'),\n",
       " ('Rreshen', 'NNP'),\n",
       " ('Vlore', 'NNP'),\n",
       " ('Elbasan', 'NNP'),\n",
       " ('Durres', 'NNP'),\n",
       " ('Shkoder', 'NNP'),\n",
       " ('Tirana', 'NNP'),\n",
       " ('Jijel', 'NNP'),\n",
       " ('Tizi-Ouzou', 'NNP'),\n",
       " ('Bordj Bou Arreridj', 'NNP'),\n",
       " (\"M'sila\", 'NNP'),\n",
       " ('Guelma', 'NNP'),\n",
       " ('Oum el Bouaghi', 'NNP'),\n",
       " ('Timimoun', 'NNP'),\n",
       " ('Sidi bel Abbes', 'NNP'),\n",
       " ('Tlimcen', 'NNP'),\n",
       " ('Beni Ounif', 'NNP'),\n",
       " ('Abadla', 'NNP'),\n",
       " ('Sefra', 'NNP'),\n",
       " ('Skikda', 'NNP'),\n",
       " ('Djanet', 'NNP'),\n",
       " ('I-n-Amenas', 'NNP'),\n",
       " ('In Amguel', 'NNP'),\n",
       " ('El Bayadh', 'NNP'),\n",
       " ('El Oued', 'NNP'),\n",
       " ('Hassi Messaoud', 'NNP'),\n",
       " ('Chlef', 'NNP'),\n",
       " ('Mascara', 'NNP'),\n",
       " ('Mostaganem', 'NNP'),\n",
       " ('Saida', 'NNP'),\n",
       " ('Tiarat', 'NNP'),\n",
       " ('Bejaia', 'NNP'),\n",
       " ('Blida', 'NNP'),\n",
       " ('Bouira', 'NNP'),\n",
       " ('Medea', 'NNP'),\n",
       " ('Souk Ahras', 'NNP'),\n",
       " ('Tebessa', 'NNP'),\n",
       " ('Adrar', 'NNP'),\n",
       " ('Reggane', 'NNP'),\n",
       " ('Bechar', 'NNP'),\n",
       " ('Tindouf', 'NNP'),\n",
       " ('Illizi', 'NNP'),\n",
       " ('Arak', 'NNP'),\n",
       " ('I-n-Salah', 'NNP'),\n",
       " ('El Golea', 'NNP'),\n",
       " ('Laghouat', 'NNP'),\n",
       " ('Touggourt', 'NNP'),\n",
       " ('Ouargla', 'NNP'),\n",
       " ('Biskra', 'NNP'),\n",
       " ('Djelfa', 'NNP'),\n",
       " ('Setif', 'NNP'),\n",
       " ('Batna', 'NNP'),\n",
       " ('Annaba', 'NNP'),\n",
       " ('Constantine', 'NNP'),\n",
       " ('Oran', 'NNP'),\n",
       " ('Tamanrasset', 'NNP'),\n",
       " ('Ghardaia', 'NNP'),\n",
       " ('Algiers', 'NNP'),\n",
       " ('Pago Pago', 'NNP'),\n",
       " ('Andorra', 'NNP'),\n",
       " ('Mucusso', 'NNP'),\n",
       " ('Lucapa', 'NNP'),\n",
       " ('Capenda-Camulemba', 'NNP'),\n",
       " ('Saurimo', 'NNP'),\n",
       " ('Muconda', 'NNP'),\n",
       " ('Cacolo', 'NNP'),\n",
       " ('Caxito', 'NNP'),\n",
       " ('Camabatela', 'NNP'),\n",
       " ('Ndalatando', 'NNP'),\n",
       " ('Quibala', 'NNP'),\n",
       " ('Calulo', 'NNP'),\n",
       " ('Waku Kungo', 'NNP'),\n",
       " ('Songo', 'NNP'),\n",
       " ('Mbanza-Congo', 'NNP'),\n",
       " ('Nzeto', 'NNP'),\n",
       " ('Soyo', 'NNP'),\n",
       " ('Cabinda', 'NNP'),\n",
       " ('Calucinga', 'NNP'),\n",
       " ('Camacupa', 'NNP'),\n",
       " ('Cubal', 'NNP'),\n",
       " ('Mavinga', 'NNP'),\n",
       " ('Cuito Caunavale', 'NNP'),\n",
       " ('Luiana', 'NNP'),\n",
       " ('Ondjiva', 'NNP'),\n",
       " ('Chitado', 'NNP'),\n",
       " ('Chibemba', 'NNP'),\n",
       " ('Chibia', 'NNP'),\n",
       " ('Quipungo', 'NNP'),\n",
       " ('Luau', 'NNP'),\n",
       " ('Cangamba', 'NNP'),\n",
       " ('Lumbala Nguimbo', 'NNP'),\n",
       " ('Cazombo', 'NNP'),\n",
       " ('Dundo', 'NNP'),\n",
       " ('Ambriz', 'NNP'),\n",
       " ('Dondo', 'NNP'),\n",
       " ('Sumbe', 'NNP'),\n",
       " ('Uige', 'NNP'),\n",
       " ('Kuito', 'NNP'),\n",
       " ('Lobito', 'NNP'),\n",
       " ('Xangongo', 'NNP'),\n",
       " ('Luena', 'NNP'),\n",
       " ('T??mbua', 'NNP'),\n",
       " ('Malanje', 'NNP'),\n",
       " ('Benguela', 'NNP'),\n",
       " ('Lubango', 'NNP'),\n",
       " ('Namibe', 'NNP'),\n",
       " ('Menongue', 'NNP'),\n",
       " ('Huambo', 'NNP'),\n",
       " ('Luanda', 'NNP'),\n",
       " ('Artigas Base', 'NNP'),\n",
       " ('Capitan Arturo Prat Station', 'NNP'),\n",
       " ('Marambio Station', 'NNP'),\n",
       " ('Zucchelli Station', 'NNP'),\n",
       " ('Rothera Station', 'NNP'),\n",
       " ('Palmer Station', 'NNP'),\n",
       " ('Base Presidente Montalva', 'NNP'),\n",
       " ('Carlini Station', 'NNP'),\n",
       " ('King Sejong Station', 'NNP'),\n",
       " ('Great Wall Station', 'NNP'),\n",
       " ('Escudero Base', 'NNP'),\n",
       " ('Elephant Island', 'NNP'),\n",
       " ('Scott Base', 'NNP'),\n",
       " ('McMurdo Station', 'NNP'),\n",
       " ('Zhongshan Station', 'NNP'),\n",
       " ('Vostok', 'NNP'),\n",
       " ('Peter I Island', 'NNP'),\n",
       " ('Mirny Station', 'NNP'),\n",
       " ('Mawson Station', 'NNP'),\n",
       " ('Davis Station', 'NNP'),\n",
       " ('Concordia Research Station', 'NNP'),\n",
       " ('Casey Station', 'NNP'),\n",
       " ('Amundsen ??Scott South Pole Station', 'NNP'),\n",
       " ('Wasa Station', 'NNP'),\n",
       " ('Troll Station', 'NNP'),\n",
       " ('Svea Station', 'NNP'),\n",
       " ('Novolazarevskaya Station', 'NNP'),\n",
       " ('Neumayer Station III', 'NNP'),\n",
       " ('Maitri Station', 'NNP'),\n",
       " ('Halley Station', 'NNP'),\n",
       " ('Belgrano Station', 'NNP'),\n",
       " ('Camp Sobral', 'NNP'),\n",
       " ('Aboa Station', 'NNP'),\n",
       " ('San Mart??n Station', 'NNP'),\n",
       " (\"Gen. O'Higgins Station\", 'NNP'),\n",
       " ('Esperanza Station', 'NNP'),\n",
       " ('Orcadas Station', 'NNP'),\n",
       " ('Signy Research Station', 'NNP'),\n",
       " (\"Dumont d'Urville Station\", 'NNP'),\n",
       " ('Showa Station', 'NNP'),\n",
       " (\"Saint John's\", 'NNP'),\n",
       " ('28 de Noviembre', 'CD'),\n",
       " ('Gobernador Gregores', 'NNP'),\n",
       " ('Comondante Luis Piedrabuena', 'NNP'),\n",
       " ('Paso Rio Mayo', 'NNP'),\n",
       " ('Alto Rio Sanguer', 'NNP'),\n",
       " ('El Maiten', 'NNP'),\n",
       " ('Puerto Madryn', 'NNP'),\n",
       " ('Trelew', 'NNP'),\n",
       " ('Las Heras', 'NNP'),\n",
       " ('San Martin', 'NNP'),\n",
       " ('Uspallata', 'NNP'),\n",
       " ('Cutral Co', 'NNP'),\n",
       " ('Punta Alta', 'NNP'),\n",
       " ('San Nicolas', 'NNP'),\n",
       " ('Campana', 'NNP'),\n",
       " ('Chacabuco', 'NNP'),\n",
       " ('Mercedes', 'NNP'),\n",
       " ('Lincoln', 'NNP'),\n",
       " ('Chivilcoy', 'NNP'),\n",
       " ('Veinticinco de Mayo', 'NNP'),\n",
       " ('Nueve de Julio', 'NNP'),\n",
       " ('Dolores', 'NNP'),\n",
       " ('Pedro Luro', 'NNP'),\n",
       " ('Tres Arroyos', 'NNP'),\n",
       " ('Coronel Suarez', 'NNP'),\n",
       " ('Balcarce', 'NNP'),\n",
       " ('25 de Mayo', 'CD'),\n",
       " ('General Roca', 'NNP'),\n",
       " ('Comallo', 'NNP'),\n",
       " ('Ingeniero Jacobacci', 'NNP'),\n",
       " ('General Conesa', 'NNP'),\n",
       " ('Choele Choel', 'NNP'),\n",
       " ('San Francisco', 'NNP'),\n",
       " ('Alta Gracia', 'NNP'),\n",
       " ('Villa Maria', 'NNP'),\n",
       " ('Bell Ville', 'NNP'),\n",
       " ('Villa Rumipal', 'NNP'),\n",
       " ('Villa Carlos Paz', 'NNP'),\n",
       " ('Chumbicha', 'NNP'),\n",
       " ('Tinogasta', 'NNP'),\n",
       " ('Abra Pampa', 'NNP'),\n",
       " ('Humahuaca', 'NNP'),\n",
       " ('Susques', 'NNP'),\n",
       " ('Chepes', 'NNP'),\n",
       " ('Yacuiba', 'NNP'),\n",
       " ('Tartagal', 'NNP'),\n",
       " ('Joaquin V. Gonzalez', 'NNP'),\n",
       " ('General Guemes', 'NNP'),\n",
       " ('Trancas', 'NNP'),\n",
       " ('Presidencia Roque Saenz Pena', 'NNP'),\n",
       " ('Pampa del Infierno', 'NNP'),\n",
       " ('Villa Angela', 'NNP'),\n",
       " ('Ingeniero Guillermo N. Juarez', 'NNP'),\n",
       " ('Comandante Fontana', 'NNP'),\n",
       " ('Doctor Pedro P. Pena', 'NNP'),\n",
       " ('San Lorenzo', 'NNP'),\n",
       " ('Corrientes', 'NNP'),\n",
       " ('Concepcion del Uruguay', 'NNP'),\n",
       " ('Victoria', 'NNP'),\n",
       " ('Gualeguay', 'NNP'),\n",
       " ('Parana', 'NNP'),\n",
       " ('Villa Constitucion', 'NNP'),\n",
       " ('Rafaela', 'NNP'),\n",
       " ('Eldorado', 'NNP'),\n",
       " ('Rodeo', 'NNP'),\n",
       " ('Las Plumas', 'NNP'),\n",
       " ('Gastre', 'NNP'),\n",
       " ('Telsen', 'NNP'),\n",
       " ('Malargue', 'NNP'),\n",
       " ('Tunuyan', 'NNP'),\n",
       " ('La Paz', 'NNP'),\n",
       " ('Chos Malal', 'NNP'),\n",
       " ('Las Lajas', 'NNP'),\n",
       " ('Zarate', 'NNP'),\n",
       " ('Carhue', 'NNP'),\n",
       " ('Darregueira', 'NNP'),\n",
       " ('Juarez', 'NNP'),\n",
       " ('Mar de Ajo', 'NNP'),\n",
       " ('Lobos', 'NNP'),\n",
       " ('Chascomus', 'NNP'),\n",
       " ('Junin', 'NNP'),\n",
       " ('La Plata', 'NNP'),\n",
       " ('Pergamino', 'NNP'),\n",
       " ('Lujan', 'NNP'),\n",
       " ('Azul', 'NNP'),\n",
       " ('Villalonga', 'NNP'),\n",
       " ('Victorica', 'NNP'),\n",
       " ('General Pico', 'NNP'),\n",
       " ('San Antonio Oeste', 'NNP'),\n",
       " ('Sierra Colorado', 'NNP'),\n",
       " ('Mercedes', 'NNP'),\n",
       " ('Rio Tercero', 'NNP'),\n",
       " ('Belen', 'NNP'),\n",
       " ('Rinconada', 'NNP'),\n",
       " ('San Pedro', 'NNP'),\n",
       " ('Libertador General San Martin', 'NNP'),\n",
       " ('Chilecito', 'NNP'),\n",
       " ('Chamical', 'NNP'),\n",
       " ('Los Blancos', 'NNP'),\n",
       " ('Cafayate', 'NNP'),\n",
       " ('Cerrillos', 'NNP'),\n",
       " ('San Antonio de los Cobres', 'NNP'),\n",
       " ('Anatuya', 'NNP'),\n",
       " ('Frias', 'NNP'),\n",
       " ('Monte Quemado', 'NNP'),\n",
       " ('Juan Jose Castelli', 'NNP'),\n",
       " ('Charata', 'NNP'),\n",
       " ('Las Lomitas', 'NNP'),\n",
       " ('Mercedes', 'NNP'),\n",
       " ('Concordia', 'NNP'),\n",
       " ('Sunchales', 'NNP'),\n",
       " ('San Justo', 'NNP'),\n",
       " ('Vera', 'NNP'),\n",
       " ('Reconquista', 'NNP'),\n",
       " ('Venado Tuerto', 'NNP'),\n",
       " ('Esquel', 'NNP'),\n",
       " ('Zapala', 'NNP'),\n",
       " ('Olavarria', 'NNP'),\n",
       " ('Tandil', 'NNP'),\n",
       " ('Viedma', 'NNP'),\n",
       " ('San Luis', 'NNP'),\n",
       " ('Rio Cuarto', 'NNP'),\n",
       " ('San Salvador de Jujuy', 'NNP'),\n",
       " ('San Ramon de la Nueva Oran', 'NNP'),\n",
       " ('Goya', 'NNP'),\n",
       " ('Puerto San Julian', 'NNP'),\n",
       " ('Perito Moreno', 'NNP'),\n",
       " ('Rio Grande', 'NNP'),\n",
       " ('Ushuaia', 'NNP'),\n",
       " ('Sarmiento', 'NNP'),\n",
       " ('San Rafael', 'NNP'),\n",
       " ('Necochea', 'NNP'),\n",
       " ('Rio Colorado', 'NNP'),\n",
       " ('Catamarca', 'NNP'),\n",
       " ('La Rioja', 'NNP'),\n",
       " ('Santiago del Estero', 'NNP'),\n",
       " ('Resistencia', 'NNP'),\n",
       " ('Gualeguaychu', 'NNP'),\n",
       " ('El Calafate', 'NNP'),\n",
       " ('San Juan', 'NNP'),\n",
       " ('Rawson', 'NNP'),\n",
       " ('Neuquen', 'NNP'),\n",
       " ('Santa Rosa', 'NNP'),\n",
       " ('San Carlos de Bariloche', 'NNP'),\n",
       " ('Salta', 'NNP'),\n",
       " ('Tucum?\\xadn', 'NNP'),\n",
       " ('Formosa', 'NNP'),\n",
       " ('Santa Fe', 'NNP'),\n",
       " ('Rosario', 'NNP'),\n",
       " ('Puerto Deseado', 'NNP'),\n",
       " ('Rio Gallegos', 'NNP'),\n",
       " ('Comodoro Rivadavia', 'NNP'),\n",
       " ('Mendoza', 'NNP'),\n",
       " ('Bahia Blanca', 'NNP'),\n",
       " ('Mar del Plata', 'NNP'),\n",
       " ('C??rdoba', 'NNP'),\n",
       " ('Posadas', 'NNP'),\n",
       " ('Buenos Aires', 'NNP'),\n",
       " ('Ashtarak', 'NNP'),\n",
       " ('Ijevan', 'NNP'),\n",
       " ('Artashat', 'NNP'),\n",
       " ('Gavarr', 'NNP'),\n",
       " ('Yeghegnadzor', 'NNP'),\n",
       " ('Gyumri', 'NNP'),\n",
       " ('Vanadzor', 'NNP'),\n",
       " ('Yerevan', 'NNP'),\n",
       " ('Oranjestad', 'NNP'),\n",
       " ('Central Coast', 'NNP'),\n",
       " ('Sunshine Coast', 'NNP'),\n",
       " ('Bourke', 'NNP'),\n",
       " ('Pine Creek', 'NNP'),\n",
       " ('Adelaide River', 'NNP'),\n",
       " ('McMinns Lagoon', 'NNP'),\n",
       " ('Newcastle Waters', 'NNP'),\n",
       " ('Ravensthorpe', 'NNP'),\n",
       " ('Wagin', 'NNP'),\n",
       " ('Roebourne', 'NNP'),\n",
       " ('Pannawonica', 'NNP'),\n",
       " ('Tom Price', 'NNP'),\n",
       " ('Kalbarri', 'NNP'),\n",
       " ('Mount Magnet', 'NNP'),\n",
       " ('Morawa', 'NNP'),\n",
       " ('Port Denison', 'NNP'),\n",
       " ('Merredin', 'NNP'),\n",
       " ('Mount Barker', 'NNP'),\n",
       " ('Katanning', 'NNP'),\n",
       " ('Narrogin', 'NNP'),\n",
       " ('Gingin', 'NNP'),\n",
       " ('Bunbury', 'NNP'),\n",
       " ('Kwinana', 'NNP'),\n",
       " ('Southern Cross', 'NNP'),\n",
       " ('Kaltukatjara', 'NNP'),\n",
       " ('Queanbeyan', 'NNP'),\n",
       " ('Tweed Heads', 'NNP'),\n",
       " ('Ivanhoe', 'NNP'),\n",
       " ('Wilcannia', 'NNP'),\n",
       " ('Merimbula', 'NNP'),\n",
       " ('Echuca', 'NNP'),\n",
       " ('Deniliquin', 'NNP'),\n",
       " ('Nowra', 'NNP'),\n",
       " ('Ulladulla', 'NNP'),\n",
       " ('Batemans Bay', 'NNP'),\n",
       " ('Cooma', 'NNP'),\n",
       " ('Tumut', 'NNP'),\n",
       " ('Leeton', 'NNP'),\n",
       " ('Young', 'NNP'),\n",
       " ('Cowra', 'NNP'),\n",
       " ('Forbes', 'NNP'),\n",
       " ('Goulburn', 'NNP'),\n",
       " ('Kiama', 'NNP'),\n",
       " ('Katoomba', 'NNP'),\n",
       " ('Richmond', 'NNP'),\n",
       " ('Lithgow', 'NNP'),\n",
       " ('Parkes', 'NNP'),\n",
       " ('Bathurst', 'NNP'),\n",
       " ('Maitland', 'NNP'),\n",
       " ('Singleton', 'NNP'),\n",
       " ('Mudgee', 'NNP'),\n",
       " ('Muswellbrook', 'NNP'),\n",
       " ('Taree', 'NNP'),\n",
       " ('Kempsey', 'NNP'),\n",
       " ('Gunnedah', 'NNP'),\n",
       " ('Coffs Harbour', 'NNP'),\n",
       " ('Narrabri', 'NNP'),\n",
       " ('Inverell', 'NNP'),\n",
       " ('Yamba', 'NNP'),\n",
       " ('Ballina', 'NNP'),\n",
       " ('Wagga Wagga', 'NNP'),\n",
       " ('Scone', 'NNP'),\n",
       " ('Byron Bay', 'NNP'),\n",
       " ('Berri', 'NNP'),\n",
       " ('Peterborough', 'NNP'),\n",
       " ('Wallaroo', 'NNP'),\n",
       " ('Clare', 'NNP'),\n",
       " ('Meningie', 'NNP'),\n",
       " ('Kingston South East', 'NNP'),\n",
       " ('Bordertown', 'NNP'),\n",
       " ('Penola', 'NNP'),\n",
       " ('Kingoonya', 'NNP'),\n",
       " ('Kimba', 'NNP'),\n",
       " ('Streaky Bay', 'NNP'),\n",
       " ('Cowell', 'NNP'),\n",
       " ('Tumby Bay', 'NNP'),\n",
       " ('Andamooka', 'NNP'),\n",
       " ('Woomera', 'NNP'),\n",
       " ('Port Pirie', 'NNP'),\n",
       " ('Gawler', 'NNP'),\n",
       " ('Murray Bridge', 'NNP'),\n",
       " ('Victor Harbor', 'NNP'),\n",
       " ('Hamilton', 'NNP'),\n",
       " ('Ouyen', 'NNP'),\n",
       " ('Colac', 'NNP'),\n",
       " ('Stawell', 'NNP'),\n",
       " ('Horsham', 'NNP'),\n",
       " ('Ararat', 'NNP'),\n",
       " ('Maryborough', 'NNP'),\n",
       " ('Bairnsdale', 'NNP'),\n",
       " ('Sale', 'NNP'),\n",
       " ('Traralgon', 'NNP'),\n",
       " ('Wonthaggi', 'NNP'),\n",
       " ('Cranbourne', 'NNP'),\n",
       " ('Ballarat', 'NNP'),\n",
       " ('Melton', 'NNP'),\n",
       " ('Seymour', 'NNP'),\n",
       " ('Shepparton', 'NNP'),\n",
       " ('Cobram', 'NNP'),\n",
       " ('Swan Hill', 'NNP'),\n",
       " ('Sunbury', 'NNP'),\n",
       " ('Proserpine', 'NNP'),\n",
       " ('Theodore', 'NNP'),\n",
       " ('Eidsvold', 'NNP'),\n",
       " ('Barcaldine', 'NNP'),\n",
       " ('Winton', 'NNP'),\n",
       " ('Longreach', 'NNP'),\n",
       " ('Caboolture', 'NNP'),\n",
       " ('Warwick', 'NNP'),\n",
       " ('Kingaroy', 'NNP'),\n",
       " ('Dalby', 'NNP'),\n",
       " ('Bongaree', 'NNP'),\n",
       " ('Gympie', 'NNP'),\n",
       " ('Ingham', 'NNP'),\n",
       " ('Birdsville', 'NNP'),\n",
       " ('Bedourie', 'NNP'),\n",
       " ('Boulia', 'NNP'),\n",
       " ('Richmond', 'NNP'),\n",
       " ('Burketown', 'NNP'),\n",
       " ('Hervey Bay', 'NNP'),\n",
       " ('Biloela', 'NNP'),\n",
       " ('Yeppoon', 'NNP'),\n",
       " ('Emerald', 'NNP'),\n",
       " ('Moranbah', 'NNP'),\n",
       " ('Charters Towers', 'NNP'),\n",
       " ('Ayr', 'NNP'),\n",
       " ('Atherton', 'NNP'),\n",
       " ('Port Douglas', 'NNP'),\n",
       " ('Smithton', 'NNP'),\n",
       " ('Scottsdale', 'NNP'),\n",
       " ('Bicheno', 'NNP'),\n",
       " ('Oatlands', 'NNP'),\n",
       " ('Queenstown', 'NNP'),\n",
       " ('Kingston', 'NNP'),\n",
       " ('Tennant Creek', 'NNP'),\n",
       " ('Yulara', 'NNP'),\n",
       " ('Erldunda', 'NNP'),\n",
       " ('Norseman', 'NNP'),\n",
       " ('Halls Creek', 'NNP'),\n",
       " ('Kununurra', 'NNP'),\n",
       " ('Derby', 'NNP'),\n",
       " ('Onslow', 'NNP'),\n",
       " ('Exmouth', 'NNP'),\n",
       " ('Carnarvon', 'NNP'),\n",
       " ('Newman', 'NNP'),\n",
       " ('Meekatharra', 'NNP'),\n",
       " ('Three Springs', 'NNP'),\n",
       " ('Manjimup', 'NNP'),\n",
       " ('Northam', 'NNP'),\n",
       " ('Esperance', 'NNP'),\n",
       " ('Leonara', 'NNP'),\n",
       " ('Laverton', 'NNP'),\n",
       " ('Wyndham', 'NNP'),\n",
       " ('Albury', 'NNP'),\n",
       " ('Forster-Tuncurry', 'NNP'),\n",
       " ('Port Macquarie', 'NNP'),\n",
       " ('Tamworth', 'NNP'),\n",
       " ('Grafton', 'NNP'),\n",
       " ('Moree', 'NNP'),\n",
       " ('Goondiwindi', 'NNP'),\n",
       " ('Lismore', 'NNP'),\n",
       " ('Wollongong', 'NNP'),\n",
       " ('Ceduna', 'NNP'),\n",
       " ('Mount Gambier', 'NNP'),\n",
       " ('Port Augusta', 'NNP'),\n",
       " ('Warrnambool', 'NNP'),\n",
       " ('Mildura', 'NNP'),\n",
       " ('Geelong', 'NNP'),\n",
       " ('Camooweal', 'NNP'),\n",
       " ('Quilpie', 'NNP'),\n",
       " ('Charleville', 'NNP'),\n",
       " ('Hughenden', 'NNP'),\n",
       " ('Caloundra', 'NNP'),\n",
       " ('Roma', 'NNP'),\n",
       " ('Toowoomba', 'NNP'),\n",
       " ('Georgetown', 'NNP'),\n",
       " ('Thargomindah', 'NNP'),\n",
       " ('Weipa', 'NNP'),\n",
       " ('Karumba', 'NNP'),\n",
       " ('Cloncurry', 'NNP'),\n",
       " ('Maryborough', 'NNP'),\n",
       " ('Bundaberg', 'NNP'),\n",
       " ('Gladstone', 'NNP'),\n",
       " ('Bowen', 'NNP'),\n",
       " ('Innisfail', 'NNP'),\n",
       " ('Mackay', 'NNP'),\n",
       " ('Burnie', 'NNP'),\n",
       " ('Launceston', 'NNP'),\n",
       " ('Katherine', 'NNP'),\n",
       " ('Busselton', 'NNP'),\n",
       " ('Mandurah', 'NNP'),\n",
       " ('Broome', 'NNP'),\n",
       " ('Kalgoorlie', 'NNP'),\n",
       " ('Albany', 'NNP'),\n",
       " ('Port Hedland', 'NNP'),\n",
       " ('Karratha', 'NNP'),\n",
       " ('Geraldton', 'NNP'),\n",
       " ('Griffith', 'NNP'),\n",
       " ('Orange', 'NNP'),\n",
       " ('Dubbo', 'NNP'),\n",
       " ('Armidale', 'NNP'),\n",
       " ('Broken Hill', 'NNP'),\n",
       " ('Port Lincoln', 'NNP'),\n",
       " ('Whyalla', 'NNP'),\n",
       " ('Portland', 'NNP'),\n",
       " ('Bendigo', 'NNP'),\n",
       " ('Wangaratta', 'NNP'),\n",
       " ('Windorah', 'NNP'),\n",
       " ('Mount Isa', 'NNP'),\n",
       " ('Rockhampton', 'NNP'),\n",
       " ('Cairns', 'NNP'),\n",
       " ('Gold Coast', 'NNP'),\n",
       " ('Devonport', 'NNP'),\n",
       " ('Darwin', 'NNP'),\n",
       " ('Alice Springs', 'NNP'),\n",
       " ('Canberra', 'NNP'),\n",
       " ('Newcastle', 'NNP'),\n",
       " ('Adelaide', 'NNP'),\n",
       " ('Townsville', 'NNP'),\n",
       " ('Brisbane', 'NNP'),\n",
       " ('Hobart', 'NNP'),\n",
       " ('Perth', 'NNP'),\n",
       " ('Melbourne', 'NNP'),\n",
       " ('Sydney', 'NNP'),\n",
       " ('Bregenz', 'NNP'),\n",
       " ('Eisenstadt', 'NNP'),\n",
       " ('Wiener Neustadt', 'NNP'),\n",
       " ('Graz', 'NNP'),\n",
       " ('Klagenfurt', 'NNP'),\n",
       " ('Linz', 'NNP'),\n",
       " ('Passau', 'NNP'),\n",
       " ('Salzburg', 'NNP'),\n",
       " ('Innsbruck', 'NNP'),\n",
       " ('Vienna', 'NNP'),\n",
       " ('Gadabay', 'NNP'),\n",
       " ('Goranboy', 'NNP'),\n",
       " ('Tovuz', 'NNP'),\n",
       " ('Agdam', 'NNP'),\n",
       " ('Qabala', 'NNP'),\n",
       " ('Oguz', 'NNP'),\n",
       " ('Ganca', 'NNP'),\n",
       " ('Yevlax', 'NNP'),\n",
       " ('Sumqayt', 'NNP'),\n",
       " ('Ali Bayramli', 'NNP'),\n",
       " ('Goycay', 'NNP'),\n",
       " ('Lankaran', 'NNP'),\n",
       " ('Saki', 'NNP'),\n",
       " ('Stepanakert', 'NNP'),\n",
       " ('Kapan', 'NNP'),\n",
       " ('Naxcivan', 'NNP'),\n",
       " ('Baku', 'NNP'),\n",
       " ('Manama', 'NNP'),\n",
       " ('Tangail', 'NNP'),\n",
       " ('Sylhet', 'NNP'),\n",
       " ('Mymensingh', 'NNP'),\n",
       " ('Jamalpur', 'NNP'),\n",
       " ('Narayanganj', 'NNP'),\n",
       " ('Jessore', 'NNP'),\n",
       " ('Barisal', 'NNP'),\n",
       " ('Comilla', 'NNP'),\n",
       " ('Pabna', 'NNP'),\n",
       " ('Nawabganj', 'NNP'),\n",
       " ('Saidpur', 'NNP'),\n",
       " ('Rangpur', 'NNP'),\n",
       " ('Khulna', 'NNP'),\n",
       " ('Rajshahi', 'NNP'),\n",
       " ('Dhaka', 'NNP'),\n",
       " ('Chittagong', 'NNP'),\n",
       " ('Bridgetown', 'NNP'),\n",
       " ('Baranavichy', 'NNP'),\n",
       " ('Polatsk', 'NNP'),\n",
       " ('Maladzyechna', 'NNP'),\n",
       " ('Pinsk', 'NNP'),\n",
       " ('Mazyr', 'NNP'),\n",
       " ('Mahilyow', 'NNP'),\n",
       " ('Babruysk', 'NNP'),\n",
       " ('Orsha', 'NNP'),\n",
       " ('Lida', 'NNP'),\n",
       " ('Hrodna', 'NNP'),\n",
       " ('Barysaw', 'NNP'),\n",
       " ('Homyel', 'NNP'),\n",
       " ('Vitsyebsk', 'NNP'),\n",
       " ('Brest', 'NNP'),\n",
       " ('Minsk', 'NNP'),\n",
       " ('Mons', 'NNP'),\n",
       " ('Hasselt', 'NNP'),\n",
       " ('Arlon', 'NNP'),\n",
       " ('Gent', 'NNP'),\n",
       " ('Liege', 'NNP'),\n",
       " ('Brugge', 'NNP'),\n",
       " ('Namur', 'NNP'),\n",
       " ('Charleroi', 'NNP'),\n",
       " ('Antwerpen', 'NNP'),\n",
       " ('Brussels', 'NNP'),\n",
       " ('El Cayo', 'NNP'),\n",
       " ('Corozal', 'NNP'),\n",
       " ('Dangriga', 'NNP'),\n",
       " ('Belize City', 'NNP'),\n",
       " ('Orange Walk', 'NNP'),\n",
       " ('Punta Gorda', 'NNP'),\n",
       " ('Belmopan', 'NNP'),\n",
       " ('Lokossa', 'NNP'),\n",
       " ('Kandi', 'NNP'),\n",
       " ('Ouidah', 'NNP'),\n",
       " ('Abomey', 'NNP'),\n",
       " ('Natitingou', 'NNP'),\n",
       " ('Djougou', 'NNP'),\n",
       " ('Parakou', 'NNP'),\n",
       " ('Porto-Novo', 'NNP'),\n",
       " ('Cotonou', 'NNP'),\n",
       " ('Hamilton', 'NNP'),\n",
       " ('Paro', 'NNP'),\n",
       " ('Punakha', 'NNP'),\n",
       " ('Wangdue Prodrang', 'NNP'),\n",
       " ('Thimphu', 'NNP'),\n",
       " ('Punata', 'NNP'),\n",
       " ('Cliza', 'NNP'),\n",
       " ('Quillacollo', 'NNP'),\n",
       " ('Puerto Villarroel', 'NNP'),\n",
       " ('Tarabuco', 'NNP'),\n",
       " ('Guayaramerin', 'NNP'),\n",
       " ('Santa Ana', 'NNP'),\n",
       " ('Baures', 'NNP'),\n",
       " ('Sica Sica', 'NNP'),\n",
       " ('Rurrenabaque', 'NNP'),\n",
       " ('Sorata', 'NNP'),\n",
       " ('Achacachi', 'NNP'),\n",
       " ('Viacha', 'NNP'),\n",
       " ('Quime', 'NNP'),\n",
       " ('Llallagua', 'NNP'),\n",
       " ('Uncia', 'NNP'),\n",
       " ('Uyuni', 'NNP'),\n",
       " ('Villa Martin', 'NNP'),\n",
       " ('Betanzos', 'NNP'),\n",
       " ('Portachuelo', 'NNP'),\n",
       " ('Samaipata', 'NNP'),\n",
       " ('Cuevo', 'NNP'),\n",
       " ('San Carlos', 'NNP'),\n",
       " ('San Lorenzo', 'NNP'),\n",
       " ('Entre Rios', 'NNP'),\n",
       " ('Aiquile', 'NNP'),\n",
       " ('Padilla', 'NNP'),\n",
       " ('Camargo', 'NNP'),\n",
       " ('Reyes', 'NNP'),\n",
       " ('San Borja', 'NNP'),\n",
       " ('Magdalena', 'NNP'),\n",
       " ('San Ramon', 'NNP'),\n",
       " ('Puerto Heath', 'NNP'),\n",
       " ('Charana', 'NNP'),\n",
       " ('Puerto Acosta', 'NNP'),\n",
       " ('Apolo', 'NNP'),\n",
       " ('Coroico', 'NNP'),\n",
       " ('Coro Coro', 'NNP'),\n",
       " ('Sabaya', 'NNP'),\n",
       " ('Challapata', 'NNP'),\n",
       " ('Llica', 'NNP'),\n",
       " ('Potosi', 'NNP'),\n",
       " ('Villazon', 'NNP'),\n",
       " ('Tupiza', 'NNP'),\n",
       " ('Montero', 'NNP'),\n",
       " ('Piso Firme', 'NNP'),\n",
       " ('Robore', 'NNP'),\n",
       " ('Puerto Quijarro', 'NNP'),\n",
       " ('San Ignacio', 'NNP'),\n",
       " ('Ascension', 'NNP'),\n",
       " ('San Javier', 'NNP'),\n",
       " ('San Rafael', 'NNP'),\n",
       " ('Vallegrande', 'NNP'),\n",
       " ('Puerto Suarez', 'NNP'),\n",
       " ('Charagua', 'NNP'),\n",
       " ('Villamontes', 'NNP'),\n",
       " ('Bermejo', 'NNP'),\n",
       " ('Cochabamba', 'NNP'),\n",
       " ('Oruro', 'NNP'),\n",
       " ('Camiri', 'NNP'),\n",
       " ('Cobija', 'NNP'),\n",
       " ('San Matias', 'NNP'),\n",
       " ('San Jos??', 'NNP'),\n",
       " ('Trinidad', 'NNP'),\n",
       " ('Tarija', 'NNP'),\n",
       " ('Sucre', 'NNP'),\n",
       " ('Riberalta', 'NNP'),\n",
       " ('La Paz', 'NNP'),\n",
       " ('Santa Cruz', 'NNP'),\n",
       " ('Zenica', 'NNP'),\n",
       " ('Mostar', 'NNP'),\n",
       " ('Tuzla', 'NNP'),\n",
       " ('Prijedor', 'NNP'),\n",
       " ('Banja Luka', 'NNP'),\n",
       " ('Sarajevo', 'NNP'),\n",
       " ('Mochudi', 'NNP'),\n",
       " ('Ghanzi', 'NNP'),\n",
       " ('Lokhwabe', 'NNP'),\n",
       " ('Lehututu', 'NNP'),\n",
       " ('Tshabong', 'NNP'),\n",
       " ('Tsau', 'NNP'),\n",
       " ('Nokaneng', 'NNP'),\n",
       " ('Mohembo', 'NNP'),\n",
       " ('Maun', 'NNP'),\n",
       " ('Kasane', 'NNP'),\n",
       " ('Nata', 'NNP'),\n",
       " ('Mopipi', 'NNP'),\n",
       " ('Palapye', 'NNP'),\n",
       " ('Lobatse', 'NNP'),\n",
       " ('Kanye', 'NNP'),\n",
       " ('Molepolole', 'NNP'),\n",
       " ('Francistown', 'NNP'),\n",
       " ('Mahalapye', 'NNP'),\n",
       " ('Serowe', 'NNP'),\n",
       " ('Gaborone', 'NNP'),\n",
       " ('Grajau', 'NNP'),\n",
       " ('Presidente Dutra', 'NNP'),\n",
       " ('Itapecuru Mirim', 'NNP'),\n",
       " ('Sao Jose de Ribamar', 'NNP'),\n",
       " ('Santa Ines', 'NNP'),\n",
       " ('Rosario', 'NNP'),\n",
       " ('Timon', 'NNP'),\n",
       " ('Capanema', 'NNP'),\n",
       " ('Portel', 'NNP'),\n",
       " ('Itupiranga', 'NNP'),\n",
       " ('Pimenta Bueno', 'NNP'),\n",
       " ('Ponta Pora', 'NNP'),\n",
       " ('Maracaju', 'NNP'),\n",
       " ('Jardim', 'NNP'),\n",
       " ('Tres Lagoas', 'NNP'),\n",
       " ('Guanhaes', 'NNP'),\n",
       " ('Leopoldina', 'NNP'),\n",
       " ('Nova Lima', 'NNP'),\n",
       " ('Pouso Alegre', 'NNP'),\n",
       " ('Itauna', 'NNP'),\n",
       " ('Caratinga', 'NNP'),\n",
       " ('Diamantina', 'NNP'),\n",
       " ('Nanuque', 'NNP'),\n",
       " ('Barbacena', 'NNP'),\n",
       " ('Pocos de Caldas', 'NNP'),\n",
       " ('Guaxupe', 'NNP'),\n",
       " ('Sao Joao del Rei', 'NNP'),\n",
       " ('Muriae', 'NNP'),\n",
       " ('Passos', 'NNP'),\n",
       " ('Conselheiro Lafaiete', 'NNP'),\n",
       " ('Formiga', 'NNP'),\n",
       " ('Frutal', 'NNP'),\n",
       " ('Iturama', 'NNP'),\n",
       " ('Ituiutaba', 'NNP'),\n",
       " ('Araguari', 'NNP'),\n",
       " ('Almenara', 'NNP'),\n",
       " ('Varzea Grande', 'NNP'),\n",
       " ('C?\\xadceres', 'NNP'),\n",
       " ('Santana do Livramento', 'NNP'),\n",
       " ('Canoas', 'NNP'),\n",
       " ('Quarai', 'NNP'),\n",
       " ('Santa Vitoria do Palmar', 'NNP'),\n",
       " ('Sao Lourenco do Sul', 'NNP'),\n",
       " ('Canela', 'NNP'),\n",
       " ('Sao Gabriel', 'NNP'),\n",
       " ('Rosario do Sul', 'NNP'),\n",
       " ('Cachoeira do Sul', 'NNP'),\n",
       " ('Osorio', 'NNP'),\n",
       " ('Santa Cruz do Sul', 'NNP'),\n",
       " ('Sao Luiz Gonzaga', 'NNP'),\n",
       " ('Santo Angelo', 'NNP'),\n",
       " ('Carazinho', 'NNP'),\n",
       " ('Erechim', 'NNP'),\n",
       " ('Guaira', 'NNP'),\n",
       " ('Palmas', 'NNP'),\n",
       " ('Arapongas', 'NNP'),\n",
       " ('Paranagua', 'NNP'),\n",
       " ('Sao Jose dos Pinhais', 'NNP'),\n",
       " ('Guarapuava', 'NNP'),\n",
       " ('Rio Negro', 'NNP'),\n",
       " ('Apucarana', 'NNP'),\n",
       " ('Lapa', 'NNP'),\n",
       " ('Irati', 'NNP'),\n",
       " ('Castro', 'NNP'),\n",
       " ('Telemaco Borba', 'NNP'),\n",
       " ('Jacarezinho', 'NNP'),\n",
       " ('Concordia', 'NNP'),\n",
       " ('Blumenau', 'NNP'),\n",
       " ('Brusque', 'NNP'),\n",
       " ('Ararangua', 'NNP'),\n",
       " ('Jaragua do Sul', 'NNP'),\n",
       " ('Tubarao', 'NNP'),\n",
       " ('Laguna', 'NNP'),\n",
       " ('Joacaba', 'NNP'),\n",
       " ('Cacador', 'NNP'),\n",
       " ('Canoinhas', 'NNP'),\n",
       " ('Camocim', 'NNP'),\n",
       " ('Russas', 'NNP'),\n",
       " ('Sobral', 'NNP'),\n",
       " ('Iguatu', 'NNP'),\n",
       " ('Quixada', 'NNP'),\n",
       " ('Caninde', 'NNP'),\n",
       " ('Campo Maior', 'NNP'),\n",
       " ('Barras', 'NNP'),\n",
       " ('Rio Largo', 'NNP'),\n",
       " ('Palmeira dos Indios', 'NNP'),\n",
       " ('Santa Cruz Cabralia', 'NNP'),\n",
       " ('Paulo Afonso', 'NNP'),\n",
       " ('Brumado', 'NNP'),\n",
       " ('Jaguaquara', 'NNP'),\n",
       " ('Itapetinga', 'NNP'),\n",
       " ('Ubaitaba', 'NNP'),\n",
       " ('Cachoeiro de Itapemirim', 'NNP'),\n",
       " ('Barra Mansa', 'NNP'),\n",
       " ('Nova Iguacu', 'NNP'),\n",
       " ('Duque de Caxias', 'NNP'),\n",
       " ('Niteroi', 'NNP'),\n",
       " ('Cabo Frio', 'NNP'),\n",
       " ('Macae', 'NNP'),\n",
       " ('Miracema', 'NNP'),\n",
       " ('Apodi', 'NNP'),\n",
       " ('Santa Cruz', 'NNP'),\n",
       " ('Morrinhos', 'NNP'),\n",
       " ('Ceres', 'NNP'),\n",
       " ('Catalao', 'NNP'),\n",
       " ('Cristalina', 'NNP'),\n",
       " ('Trindade', 'NNP'),\n",
       " ('Ipora', 'NNP'),\n",
       " ('Inhumas', 'NNP'),\n",
       " ('Itaberai', 'NNP'),\n",
       " ('Santo Andre', 'NNP'),\n",
       " ('Pindamonhangaba', 'NNP'),\n",
       " ('Rio Claro', 'NNP'),\n",
       " ('Ourinhos', 'NNP'),\n",
       " ('Itanhaem', 'NNP'),\n",
       " ('Jaboticabal', 'NNP'),\n",
       " ('Braganca Paulista', 'NNP'),\n",
       " ('Jundiai', 'NNP'),\n",
       " ('Sao Jose dos Campos', 'NNP'),\n",
       " ('Guaratingueta', 'NNP'),\n",
       " ('Pirassununga', 'NNP'),\n",
       " ('Americana', 'NNP'),\n",
       " ('Piracicaba', 'NNP'),\n",
       " ('Sao Joao da Boa Vista', 'NNP'),\n",
       " ('Sao Carlos', 'NNP'),\n",
       " ('Tupa', 'NNP'),\n",
       " ('Penapolis', 'NNP'),\n",
       " ('Presidente Prudente', 'NNP'),\n",
       " ('Registro', 'NNP'),\n",
       " ('Tatui', 'NNP'),\n",
       " ('Avare', 'NNP'),\n",
       " ('Garca', 'NNP'),\n",
       " ('Catanduva', 'NNP'),\n",
       " ('Batatais', 'NNP'),\n",
       " ('Barretos', 'NNP'),\n",
       " ('Marilia', 'NNP'),\n",
       " ('Itu', 'NNP'),\n",
       " ('Itapetininga', 'NNP'),\n",
       " ('Jaboatao', 'NNP'),\n",
       " ('Olinda', 'NNP'),\n",
       " ('Cabo de Santo Agostinho', 'NNP'),\n",
       " ('Carpina', 'NNP'),\n",
       " ('Arcoverde', 'NNP'),\n",
       " ('Manacapuru', 'NNP'),\n",
       " ('Maues', 'NNP'),\n",
       " ('Pedreiras', 'NNP'),\n",
       " ('Codo', 'NNP'),\n",
       " ('Coroata', 'NNP'),\n",
       " ('Chapadinha', 'NNP'),\n",
       " ('Pinheiro', 'NNP'),\n",
       " ('Barra do Corda', 'NNP'),\n",
       " ('Viana', 'NNP'),\n",
       " ('Colinas', 'NNP'),\n",
       " ('Viseu', 'NNP'),\n",
       " ('Capitao Poco', 'NNP'),\n",
       " ('Castanhal', 'NNP'),\n",
       " ('Salinopolis', 'NNP'),\n",
       " ('Alenquer', 'NNP'),\n",
       " ('Oriximina', 'NNP'),\n",
       " ('Xinguara', 'NNP'),\n",
       " ('Jacund?\\xad', 'NNP'),\n",
       " ('Uruara', 'NNP'),\n",
       " ('Altamira', 'NNP'),\n",
       " ('Paragominas', 'NNP'),\n",
       " ('Cameta', 'NNP'),\n",
       " ('Rolim de Moura', 'NNP'),\n",
       " ('Ariquemes', 'NNP'),\n",
       " ('Abuna', 'NNP'),\n",
       " ('Tocantinopolis', 'NNP'),\n",
       " ('Gurupi', 'NNP'),\n",
       " ('Aquidauana', 'NNP'),\n",
       " ('Paranaiba', 'NNP'),\n",
       " ('Sete Lagoas', 'NNP'),\n",
       " ('Divinopolis', 'NNP'),\n",
       " ('Ipatinga', 'NNP'),\n",
       " ('Araxa', 'NNP'),\n",
       " ('Lavras', 'NNP'),\n",
       " ('Uba', 'NNP'),\n",
       " ('Campo Belo', 'NNP'),\n",
       " ('Ponte Nova', 'NNP'),\n",
       " ('Curvelo', 'NNP'),\n",
       " ('Paracatu', 'NNP'),\n",
       " ('Bocaiuva', 'NNP'),\n",
       " ('Aracuai', 'NNP'),\n",
       " ('Janauba', 'NNP'),\n",
       " ('Juina', 'NNP'),\n",
       " ('Barra do Garcas', 'NNP'),\n",
       " ('Pontes e Lacerda', 'NNP'),\n",
       " ('Barra do Bugres', 'NNP'),\n",
       " ('Rondonopolis', 'NNP'),\n",
       " ('Uruguaiana', 'NNP'),\n",
       " ('Sao Borja', 'NNP'),\n",
       " ('Novo Hamburgo', 'NNP'),\n",
       " ('Rio Grande', 'NNP'),\n",
       " ('Camaqua', 'NNP'),\n",
       " ('Bento Goncalves', 'NNP'),\n",
       " ('Vacaria', 'NNP'),\n",
       " ('Ijui', 'NNP'),\n",
       " ('Santa Rosa', 'NNP'),\n",
       " ('Maringa', 'NNP'),\n",
       " ('Cascavel', 'NNP'),\n",
       " ('Campo Murao', 'NNP'),\n",
       " ('Foz do Iguacu', 'NNP'),\n",
       " ('Sao Francisco do Sul', 'NNP'),\n",
       " ('Porto Uniao', 'NNP'),\n",
       " ('Itajai', 'NNP'),\n",
       " ('Imbituba', 'NNP'),\n",
       " ('Lajes', 'NNP'),\n",
       " ('Granja', 'NNP'),\n",
       " ('Crato', 'NNP'),\n",
       " ('Itapipoca', 'NNP'),\n",
       " ('Paracuru', 'NNP'),\n",
       " ('Acarau', 'NNP'),\n",
       " ('Taua', 'NNP'),\n",
       " ('Crateus', 'NNP'),\n",
       " ('Baturite', 'NNP'),\n",
       " ('Ipu', 'NNP'),\n",
       " ('Floriano', 'NNP'),\n",
       " ('Piripiri', 'NNP'),\n",
       " ('Penedo', 'NNP'),\n",
       " ...]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.pos_tag(worldcities['city'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "2873b722",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import TreebankWordTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "51edd7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tok = TreebankWordTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "3427988f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Qal', 'eh-ye', 'Now']"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tok.tokenize(worldcities['city'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "f916d615",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Chaghcharan']"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tok.tokenize(worldcities['city'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "f1902957",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Mahmud-E', 'Eraqi']"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tok.tokenize(worldcities['city'][8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "17550f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import PunktSentenceTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "68a48622",
   "metadata": {},
   "outputs": [],
   "source": [
    "tok = PunktSentenceTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "30ca51bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Qal eh-ye Now']"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tok.tokenize(worldcities['city'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "df5099e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Mahmud-E Eraqi']"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tok.tokenize(worldcities['city'][8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "79f58351",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AF']"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tok.tokenize(worldcities['iso2'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "12f330f3",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cannot use a string pattern on a bytes-like object",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[100], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtok\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtokenize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mworldcities\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpop\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# not working in obj\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\nltk\\tokenize\\punkt.py:1281\u001b[0m, in \u001b[0;36mPunktSentenceTokenizer.tokenize\u001b[1;34m(self, text, realign_boundaries)\u001b[0m\n\u001b[0;32m   1277\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtokenize\u001b[39m(\u001b[38;5;28mself\u001b[39m, text: \u001b[38;5;28mstr\u001b[39m, realign_boundaries: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[\u001b[38;5;28mstr\u001b[39m]:\n\u001b[0;32m   1278\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1279\u001b[0m \u001b[38;5;124;03m    Given a text, returns a list of the sentences in that text.\u001b[39;00m\n\u001b[0;32m   1280\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1281\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msentences_from_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrealign_boundaries\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\nltk\\tokenize\\punkt.py:1341\u001b[0m, in \u001b[0;36mPunktSentenceTokenizer.sentences_from_text\u001b[1;34m(self, text, realign_boundaries)\u001b[0m\n\u001b[0;32m   1332\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msentences_from_text\u001b[39m(\n\u001b[0;32m   1333\u001b[0m     \u001b[38;5;28mself\u001b[39m, text: \u001b[38;5;28mstr\u001b[39m, realign_boundaries: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   1334\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[\u001b[38;5;28mstr\u001b[39m]:\n\u001b[0;32m   1335\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1336\u001b[0m \u001b[38;5;124;03m    Given a text, generates the sentences in that text by only\u001b[39;00m\n\u001b[0;32m   1337\u001b[0m \u001b[38;5;124;03m    testing candidate sentence breaks. If realign_boundaries is\u001b[39;00m\n\u001b[0;32m   1338\u001b[0m \u001b[38;5;124;03m    True, includes in the sentence closing punctuation that\u001b[39;00m\n\u001b[0;32m   1339\u001b[0m \u001b[38;5;124;03m    follows the period.\u001b[39;00m\n\u001b[0;32m   1340\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1341\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m[\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m[\u001b[49m\u001b[43ms\u001b[49m\u001b[43m:\u001b[49m\u001b[43me\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43me\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mspan_tokenize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrealign_boundaries\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\nltk\\tokenize\\punkt.py:1341\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   1332\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msentences_from_text\u001b[39m(\n\u001b[0;32m   1333\u001b[0m     \u001b[38;5;28mself\u001b[39m, text: \u001b[38;5;28mstr\u001b[39m, realign_boundaries: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   1334\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[\u001b[38;5;28mstr\u001b[39m]:\n\u001b[0;32m   1335\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1336\u001b[0m \u001b[38;5;124;03m    Given a text, generates the sentences in that text by only\u001b[39;00m\n\u001b[0;32m   1337\u001b[0m \u001b[38;5;124;03m    testing candidate sentence breaks. If realign_boundaries is\u001b[39;00m\n\u001b[0;32m   1338\u001b[0m \u001b[38;5;124;03m    True, includes in the sentence closing punctuation that\u001b[39;00m\n\u001b[0;32m   1339\u001b[0m \u001b[38;5;124;03m    follows the period.\u001b[39;00m\n\u001b[0;32m   1340\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1341\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [text[s:e] \u001b[38;5;28;01mfor\u001b[39;00m s, e \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspan_tokenize(text, realign_boundaries)]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\nltk\\tokenize\\punkt.py:1329\u001b[0m, in \u001b[0;36mPunktSentenceTokenizer.span_tokenize\u001b[1;34m(self, text, realign_boundaries)\u001b[0m\n\u001b[0;32m   1327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m realign_boundaries:\n\u001b[0;32m   1328\u001b[0m     slices \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_realign_boundaries(text, slices)\n\u001b[1;32m-> 1329\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sentence \u001b[38;5;129;01min\u001b[39;00m slices:\n\u001b[0;32m   1330\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m (sentence\u001b[38;5;241m.\u001b[39mstart, sentence\u001b[38;5;241m.\u001b[39mstop)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\nltk\\tokenize\\punkt.py:1459\u001b[0m, in \u001b[0;36mPunktSentenceTokenizer._realign_boundaries\u001b[1;34m(self, text, slices)\u001b[0m\n\u001b[0;32m   1446\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1447\u001b[0m \u001b[38;5;124;03mAttempts to realign punctuation that falls after the period but\u001b[39;00m\n\u001b[0;32m   1448\u001b[0m \u001b[38;5;124;03mshould otherwise be included in the same sentence.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1456\u001b[0m \u001b[38;5;124;03m    [\"(Sent1.)\", \"Sent2.\"].\u001b[39;00m\n\u001b[0;32m   1457\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1458\u001b[0m realign \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m-> 1459\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sentence1, sentence2 \u001b[38;5;129;01min\u001b[39;00m _pair_iter(slices):\n\u001b[0;32m   1460\u001b[0m     sentence1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mslice\u001b[39m(sentence1\u001b[38;5;241m.\u001b[39mstart \u001b[38;5;241m+\u001b[39m realign, sentence1\u001b[38;5;241m.\u001b[39mstop)\n\u001b[0;32m   1461\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m sentence2:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\nltk\\tokenize\\punkt.py:321\u001b[0m, in \u001b[0;36m_pair_iter\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m    319\u001b[0m iterator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28miter\u001b[39m(iterator)\n\u001b[0;32m    320\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 321\u001b[0m     prev \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(iterator)\n\u001b[0;32m    322\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[0;32m    323\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\nltk\\tokenize\\punkt.py:1431\u001b[0m, in \u001b[0;36mPunktSentenceTokenizer._slices_from_text\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m   1429\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_slices_from_text\u001b[39m(\u001b[38;5;28mself\u001b[39m, text: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator[\u001b[38;5;28mslice\u001b[39m]:\n\u001b[0;32m   1430\u001b[0m     last_break \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m-> 1431\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m match, context \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_match_potential_end_contexts(text):\n\u001b[0;32m   1432\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtext_contains_sentbreak(context):\n\u001b[0;32m   1433\u001b[0m             \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28mslice\u001b[39m(last_break, match\u001b[38;5;241m.\u001b[39mend())\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\nltk\\tokenize\\punkt.py:1395\u001b[0m, in \u001b[0;36mPunktSentenceTokenizer._match_potential_end_contexts\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m   1393\u001b[0m previous_slice \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mslice\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m   1394\u001b[0m previous_match \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1395\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m match \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_lang_vars\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mperiod_context_re\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfinditer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m   1396\u001b[0m \n\u001b[0;32m   1397\u001b[0m     \u001b[38;5;66;03m# Get the slice of the previous word\u001b[39;00m\n\u001b[0;32m   1398\u001b[0m     before_text \u001b[38;5;241m=\u001b[39m text[previous_slice\u001b[38;5;241m.\u001b[39mstop : match\u001b[38;5;241m.\u001b[39mstart()]\n\u001b[0;32m   1399\u001b[0m     index_after_last_space \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_last_whitespace_index(before_text)\n",
      "\u001b[1;31mTypeError\u001b[0m: cannot use a string pattern on a bytes-like object"
     ]
    }
   ],
   "source": [
    "tok.tokenize(worldcities['pop'][0]) # not working in obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "60856113",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "39987028",
   "metadata": {},
   "outputs": [],
   "source": [
    "worldcities_wordnet = worldcities['city'].apply(wordnet.synsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "ed4bf761",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                              []\n",
       "1                              []\n",
       "2                              []\n",
       "3                              []\n",
       "4                              []\n",
       "                  ...            \n",
       "7317                           []\n",
       "7318                           []\n",
       "7319                           []\n",
       "7320      [Synset('harare.n.01')]\n",
       "7321    [Synset('bulawayo.n.01')]\n",
       "Name: city, Length: 7322, dtype: object"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "worldcities_wordnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "19622287",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "0f8be1c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "worldcities['Filtered_city'] = worldcities['tokenized_city'].apply(lambda x:[word for word in x if word.lower() not in stop_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "221ced27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         [Qal, eh-ye]\n",
       "1        [Chaghcharan]\n",
       "2       [Lashkar, Gah]\n",
       "3             [Zaranj]\n",
       "4        [Tarin, Kowt]\n",
       "             ...      \n",
       "7317          [Mutare]\n",
       "7318          [Kadoma]\n",
       "7319     [Chitungwiza]\n",
       "7320          [Harare]\n",
       "7321        [Bulawayo]\n",
       "Name: Filtered_city, Length: 7322, dtype: object"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "worldcities['Filtered_city']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "c8f5163b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "c3898ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "worldcities['Lemmatized_City'] = worldcities['Filtered_city'].apply(lambda x: [lemmatizer.lemmatize(word) for word in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "73b8884c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         [Qal, eh-ye]\n",
       "1        [Chaghcharan]\n",
       "2       [Lashkar, Gah]\n",
       "3             [Zaranj]\n",
       "4        [Tarin, Kowt]\n",
       "             ...      \n",
       "7317          [Mutare]\n",
       "7318          [Kadoma]\n",
       "7319     [Chitungwiza]\n",
       "7320          [Harare]\n",
       "7321        [Bulawayo]\n",
       "Name: Lemmatized_City, Length: 7322, dtype: object"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "worldcities['Lemmatized_City']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "9c3b8f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "18a9c57d",
   "metadata": {},
   "outputs": [],
   "source": [
    "blob=TextBlob(worldcities['city'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "0d35f8c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextBlob(\"Qal eh-ye Now\")"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "cc984ff5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextBlob(\"Qal eh-ye ahora\")"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob.translate(from_lang=\"en\",to=\"es\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "017687de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextBlob(\"Qal eh-ye maintenant\")"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob.translate(from_lang=\"en\",to=\"fr\") # france"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "80ef5a89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TextBlob(worldcities['city'][0]).sentiment.polarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "e6d9f1d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TextBlob(worldcities['country'][0]).sentiment.polarity"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
